
# Visual Genius: Communication Assistant

Most children with autism spectrum disorders (ASD) are visual learners. They tend to comprehend visual information better than auditory input, making visual supports more effective for their learning process.

## Core Features

1. Switching between personas and modes of generation (List, Steps, Manual / Parents and Caregivers, Childs)
1. Visual Card generation and management
1. Semantic Image search
1. Video generation from images (To teach work procedures)
1. Image search and Text-to-Image

## Technology stack

1. Vector-based image search (Semantic image search, Azure Cognitive Search + Use Florence Vision API for Vector embedding)
1. Text-to-image generation (Azure OpenAI GPT-3.5, Image Generation by Azure OpenAI Dall-E) : Due to the Generation speed issue, only the last image will be generated by this method.
1. Image collection management (Arrange images by Drag and Drop)
1. Bing Image Search
1. Microsoft Coco dataset (Everyday Life images)
1. Azure Cognitive Services Speech to Text (Read a text on the card)

## Why did you start planning this project?

1. <b>Personal experience</b>: I took part in an activity involving the creation of a visual card. The activity required cutting an image from a book and covering it with a laminated sheet, which was then heated to attach it to the image. However, I found this process to be extremely time-consuming and challenging considering the final outcome.

2. <b>Market demands</b>: My team's market research revealed that the existing products in this particular niche market were both expensive and of inferior quality. It was apparent that there was an opportunity to provide a better solution for consumers.

3. <b>Democratizing AI</b>: One of the core objectives of this project is to harness the power of Generative AI and make it accessible to everyone.

    Before the advent of technologies like LLM (Large Language Model), performing simple sentiment analysis on customer reviews required a significant investment of time and resources, often taking up to several months to build and evaluate a model using traditional methods.

    In the previous version, we encountered challenges in providing an image-searching feature and every item needs to be inputted by a user. Text completion and embedding API are able to resolve these issues.

## Configure Development environment

  Note: Please ensure you have installed <code><a href="https://nodejs.org/en/download/">nodejs</a></code> and python3.

  To preview and run the project on your device:

  1. Open project folder in <a href="https://code.visualstudio.com/download">Visual Studio Code</a>
  2. In the terminal, run `npm install`
  3. Run `npm run dev` to view project in browser
  4. Run `python app` to launch the backend.

  !important: `react-beautiful-dnd` was not able to work well with `reactStrictMode: true` in NextJs.
  Turn off the option at `next.config.js`.`

## Data Loading

  1. Uploading your data into Azure Blob Storage. 
    dataset > data > Upload to Blob image container
    dataset > emoji > Upload to Blob emoji container
  1. Image and Category are managed on SQL Database. > DB Creation: `backend\infra\db_postgres.sql` > DB Data Generate: `backend\util\postgre_gen_db_data.py`
  1. Image search requires to create Azure Cognitive Search Index. > `backend\util\acs_index_gen.py` > trigger indexer 
    
      > The web skill (azure functions: acs_skillset_for_indexer) should be deployed before it is triggered.

  1. Update and sync the sid attribute in Azure Cognitive Search by metadata in SQL database > `backend\util\data_for_dev\acs_index_mapping_with_postgre.py`

Data creation for development and Dataset. Please find the sample images in `dataset` and `backend\util` directories.

## API Specification

  http://localhost:5000/docs

## Preview

https://github.com/kimtth/visual-genius/assets/13846660/7a39a3ba-32e7-4742-aea6-c288df2bc766

## Demo application to Azure

1. Deploy Azure Resources

  Set up your parameters for Azure Bicep

  ```json
  "prefix": {
      "value": "<your-value-for-prefix>"
  },
  "pgsqlId": {
      "value": "<your-postgre-sql-id>"
  },
  "pgsqlPwd": {
      "value": "<your-postgre-sql-password>"
  }
  ```

  Execute the script for Azure Bicep

  ```powershell
  PS> .\main.ps1 -resourceGroup <your-resource-group-name> -location <your-resource-location>
  ```

2. Build Next.js application

  ```json
  "scripts": {
      "dev": "next dev",
      "build": "next build && next export -o backend/public",
      "start": "next start",
      "lint": "next lint"
  }
  ```

  The `.env.production` on root will be embedded into the javascript files.

  ```
  API_ENDPOINT=
  ENV_TYPE=prod
  ```

  Build UI code.

  ```nodejs
  npm run build
  ```

This will create `public` directory in the `backend`.

3. Upload UI and python code to Azure App Service

    - [Tutorial](https://learn.microsoft.com/en-us/azure/app-service/quickstart-python?tabs=flask%2Cwindows%2Cvscode-aztools%2Cvscode-deploy%2Cdeploy-instructions-azportal%2Cterminal-bash%2Cdeploy-instructions-zip-azcli)

4. To set up the start up command at Azure App service.

    1. Open your Web App in the Azure Portal.
    1. Scroll to Configuration under Settings.
    1. Click on the General Settings tab.
    1. Enter the appropriate startup command.

  ```python
  python app.py
  ```

5. To set up environment variables in Azure App Service, you can follow these steps:

    In the Azure Portal, locate your App Service.
    1. On the left pane, click on “Configuration”.
    1. Under “Application settings”, click on “New application setting”.
    1. Fill in the name and value for each environment variable:
    1. Click “OK”, then at the top, click "Save".

        ```bash
        AZURE_SEARCH_SERVICE_ENDPOINT=https://?.search.windows.net
        AZURE_SEARCH_INDEX_NAME=
        AZURE_SEARCH_ADMIN_KEY=
        COGNITIVE_SERVICES_ENDPOINT=https://?.cognitiveservices.azure.com
        COGNITIVE_SERVICES_API_KEY=
        BLOB_CONNECTION_STRING=
        BLOB_CONTAINER_NAME=
        BLOB_EMOJI_CONTAINER_NAME=
        AZURE_OPENAI_ENDPOINT=https://?.openai.azure.com/
        AZURE_OPENAI_API_KEY=
        AZURE_OPENAI_API_VERSION_IMG=2023-06-01-preview
        AZURE_OPENAI_API_VERSION_CHAT=2023-07-01-preview
        BING_IMAGE_SEARCH_KEY=
        SPEECH_SUBSCRIPTION_KEY=
        SPEECH_REGION=
        POSTGRE_HOST=
        POSTGRE_USER=
        POSTGRE_PORT=5432
        POSTGRE_DATABASE=
        POSTGRE_PASSWORD=
        ENV_TYPE=PROD
        APP_SECRET_STRING=
        ```

6. Test user

    - User ID:Password - sys:sys

7. PostgreSQL offers a vector search feature through the installation of the pgvector plugin. This feature can be utilized to implement image search, potentially serving as an alternative to Azure Cognitive Search. However, it’s important to note that PostgreSQL is not optimized for vector search.


